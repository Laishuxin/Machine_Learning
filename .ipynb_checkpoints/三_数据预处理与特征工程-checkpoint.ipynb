{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据挖掘的五大流程  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 获取数据\n",
    "2. **数据预处理**\n",
    "数据预处理是从数据中检测，纠正或删除损坏，不准确或不适用于模型的记录的过程\n",
    "可能面对的问题有：数据类型不同，比如有的是文字，有的是数字，有的含时间序列，有的连续，有的间断。\n",
    "也可能，数据的质量不行，有噪声，有异常，有缺失，数据出错，量纲不一，有重复，数据是偏态，数据量太\n",
    "大或太小\n",
    "数据预处理的目的：让数据适应模型，匹配模型的需求\n",
    "3. **特征工程**：\n",
    "特征工程是将原始数据转换为更能代表预测模型的潜在问题的特征的过程，可以通过挑选最相关的特征，提取\n",
    "特征以及创造特征来实现。其中创造特征又经常以降维算法的方式实现。\n",
    "可能面对的问题有：特征之间有相关性，特征和标签无关，特征太多或太小，或者干脆就无法表现出应有的数\n",
    "据现象或无法展示数据的真实面貌\n",
    "特征工程的目的：1) 降低计算成本，2) 提升模型上限\n",
    "4. 建模，测试模型并预测出结果\n",
    "5. 上线，验证模型效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn中的数据预处理与特征工程模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 模块preprocessing：几乎包含数据预处理的所有内容\n",
    "+ 模块Impute：填补缺失值专用\n",
    "+ 模块feature_selection：包含特征选择的各种方法的实践\n",
    "+ 模块decomposition：包含降维算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理 Precessing &Impute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据无量纲化(去单位化)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在机器学习算法实践中，我们往往有着将不同规格的数据转换到同一规格，或不同分布的数据转换到某个特定分布\n",
    "的需求，这种需求统称为将数据“无量纲化”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "譬如梯度和矩阵为核心的算法中，譬如逻辑回归，支持向量机，神经\n",
    "网络，无量纲化可以加快求解速度；而在距离类模型，譬如K近邻，K-Means聚类中，无量纲化可以帮我们提升模\n",
    "型精度，避免某一个取值范围特别大的特征对距离计算造成影响。（一个特例是决策树和树的集成算法们，对决策\n",
    "树我们不需要无量纲化，决策树可以把任意数据都处理得很好。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据的无量纲化可以是线性的，也可以是非线性的。线性的无量纲化包括**中心化**（Zero-centered或者Mean-subtraction）处理和**缩放处理**（Scale）。**中心化的本质是让所有记录减去一个固定值，即让数据样本数据平移到\n",
    "某个位置**。**缩放的本质是通过除以一个固定值，将数据固定在某个范围之中**，取对数也算是一种缩放处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### preprocessing.MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当数据(x)按照**最小值**中心化后，再按**极差（最大值 - 最小值）缩放**，数据移动了最小值个单位，并且会被收敛到\n",
    "[0,1]之间，而这个过程，就叫做数据**归一化**(Normalization，又称Min-Max Scaling)。注意，Normalization是归\n",
    "一化，不是正则化，真正的正则化是regularization，不是数据预处理的一种手段。归一化之后的数据服从正态分\n",
    "布，公式如下:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 归一化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">归一化：１）把数据变成(０，１)之间的小数。主要是为了数据处理方便提出来的，把数据映射到0～1范围之内处理，更加便捷快速。２）把有量纲表达式变成无量纲表达式，便于不同单位或量级的指标能够进行比较和加权。归一化是一种简化计算的方式，即将有量纲的表达式，经过变换，化为无量纲的表达式，成为纯量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "归一化:  \n",
    "+ Max-min-normalization  \n",
    "$$\\dfrac{x - x_{min}}{x_{max} - x_{min}}$$  \n",
    "+ 均值归一化  \n",
    "$$\\dfrac{x - \\mu}{x_{max} - x_{min}}$$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "缺点：当有新数据加入时，可能导致max和min的变化，需要重新定义。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ 非线性归一化\n",
    "    + 对数函数转换：y = log10(x)\n",
    "    + 反余切函数转换：y = atan(x) * 2 / π\n",
    "\n",
    "经常用在数据分化比较大的场景，有些数值很大，有些很小。通过一些数学函数，将原始值进行映射。该方法包括 log、指数，正切等。需要根据数据分布的情况，决定非线性函数的曲线，比如log(V, 2)还是log(V, 10)等。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">标准化：在机器学习中，我们可能要处理不同种类的资料，例如，音讯和图片上的像素值，这些资料可能是高维度的，资料标准化后会使每个特征中的数值平均变为0(将每个特征的值都减掉原始资料中该特征的平均)、标准差变为1，这个方法被广泛的使用在许多机器学习算法中(例如：支持向量机、逻辑回归和类神经网络)。\n",
    "\n",
    "标准化：  \n",
    "$$\\dfrac{x - \\mu}{\\sigma} \\;\\;\\;(其中，\\mu为x的平均值,\\sigma为x的标准差)$$\n",
    "\n",
    ">中心化：平均值为0，对标准差无要求\n",
    "\n",
    "##### 中心化\n",
    "中心化：  \n",
    "$$x - \\mu$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 为什么要归一化/标准化？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "归一化/标准化实质是一种线性变换，线性变换有很多良好的性质，这些性质决定了对数据改变后不会造成“失效”，反而能提高数据的表现，这些性质是归一化/标准化的前提。比如有一个很重要的性质：线性变换不会改变原始数据的数值排序。  \n",
    "1. 某些模型求解需要  \n",
    "\n",
    "    + 在使用梯度下降的方法求解最优化问题时， 归一化/标准化后可以加快梯度下降的求解速度，即提升模型的收敛速度。如左图所示，未归一化/标准化时形成的等高线偏椭圆，迭代时很有可能走“之”字型路线（垂直长轴），从而导致迭代。  很多次才能收敛。而如右图对两个特征进行了归一化，对应的等高线就会变圆，在梯度下降进行求解时能较快的收敛。\n",
    "\n",
    "![](images/3_1.png)  \n",
    "\n",
    "+ 一些分类器需要计算样本之间的距离(如欧氏距离)，例如KNN。如果一个特征值域范围非常大，那么距离计算就主要取决于这个特征，从而与实际情况相悖(比如这时实际情况是值域范围小的特征更重要)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 归一化sklearn实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T09:56:23.272238Z",
     "start_time": "2019-12-10T09:56:23.262322Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T09:56:23.641266Z",
     "start_time": "2019-12-10T09:56:23.629359Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.array([[-1, 2], [-0.5, 6], [0, 10], [1, 18]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T09:56:23.948894Z",
     "start_time": "2019-12-10T09:56:23.931426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.5</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1\n",
       "0 -1.0   2.0\n",
       "1 -0.5   6.0\n",
       "2  0.0  10.0\n",
       "3  1.0  18.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在归一化到0-1范围"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T09:56:58.503965Z",
     "start_time": "2019-12-10T09:56:58.497518Z"
    }
   },
   "outputs": [],
   "source": [
    "# 实现归一化\n",
    "scaler = MinMaxScaler()\n",
    "scaler = scaler.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T09:57:13.138722Z",
     "start_time": "2019-12-10T09:57:13.119858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  ],\n",
       "       [0.25, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [1.  , 1.  ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T09:57:58.674959Z",
     "start_time": "2019-12-10T09:57:58.656553Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  ],\n",
       "       [0.25, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [1.  , 1.  ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一步到位\n",
    "result = MinMaxScaler().fit_transform(data)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T09:59:43.412879Z",
     "start_time": "2019-12-10T09:59:43.397297Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  ],\n",
       "       [0.25, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [1.  , 1.  ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 实现复原效果\n",
    "scaler = MinMaxScaler().fit(data)\n",
    "result = scaler.transform(data)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T10:00:02.344722Z",
     "start_time": "2019-12-10T10:00:02.329349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. ,  2. ],\n",
       "       [-0.5,  6. ],\n",
       "       [ 0. , 10. ],\n",
       "       [ 1. , 18. ]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 归一化到指定范围\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T10:01:41.243321Z",
     "start_time": "2019-12-10T10:01:41.228816Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(5, 10)).fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T10:02:06.383114Z",
     "start_time": "2019-12-10T10:02:06.362181Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.  ,  5.  ],\n",
       "       [ 6.25,  6.25],\n",
       "       [ 7.5 ,  7.5 ],\n",
       "       [10.  , 10.  ]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用numpy实现归一化  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T10:03:31.968948Z",
     "start_time": "2019-12-10T10:03:31.961015Z"
    }
   },
   "outputs": [],
   "source": [
    "data_norm = (data - data.min(axis=0))  / (data.max(axis=0) - data.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T10:03:42.764169Z",
     "start_time": "2019-12-10T10:03:42.743333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  ],\n",
       "       [0.25, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [1.  , 1.  ]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T10:06:05.495954Z",
     "start_time": "2019-12-10T10:06:05.477601Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. ,  2. ],\n",
       "       [-0.5,  6. ],\n",
       "       [ 0. , 10. ],\n",
       "       [ 1. , 18. ]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 反归一化\n",
    "data_norm * (data.max(axis=0) - data.min(axis=0)) + data.min(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T10:05:12.841601Z",
     "start_time": "2019-12-10T10:05:12.832173Z"
    }
   },
   "source": [
    "## 标准化sklearn实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当数据(x)按均值(μ)中心化后，再按标准差(σ)缩放，数据就会服从为均值为0，方差为1的正态分布（即标准正态分\n",
    "布），而这个过程，就叫做数据标准化(Standardization，又称Z-score normalization)，公式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x^{*} = \\dfrac{x- \\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T10:57:54.287021Z",
     "start_time": "2019-12-10T10:57:54.274036Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T10:58:12.169192Z",
     "start_time": "2019-12-10T10:58:12.161255Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.array([[-1, 2], [-0.5, 6], [0, 10], [1, 18]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T10:58:26.509811Z",
     "start_time": "2019-12-10T10:58:26.499818Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T10:59:13.817997Z",
     "start_time": "2019-12-10T10:59:13.799469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.125,  9.   ])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T10:59:24.126056Z",
     "start_time": "2019-12-10T10:59:24.115409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.546875, 35.      ])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T10:59:24.494528Z",
     "start_time": "2019-12-10T10:59:24.473390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.18321596, -1.18321596],\n",
       "       [-0.50709255, -0.50709255],\n",
       "       [ 0.16903085,  0.16903085],\n",
       "       [ 1.52127766,  1.52127766]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T11:00:23.060712Z",
     "start_time": "2019-12-10T11:00:23.038180Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.18321596, -1.18321596],\n",
       "       [-0.50709255, -0.50709255],\n",
       "       [ 0.16903085,  0.16903085],\n",
       "       [ 1.52127766,  1.52127766]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 一步到位\n",
    "StandardScaler().fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于StandardScaler和MinMaxScaler来说，空值NaN会被当做是缺失值，在fit的时候忽略，在transform的时候\n",
    "保持缺失NaN的状态显示。并且，尽管去量纲化过程不是具体的算法，但在fit接口中，依然只允许导入至少二维数\n",
    "组，一维数组导入会报错。通常来说，我们输入的X会是我们的特征矩阵，现实案例中特征矩阵不太可能是一维所\n",
    "以不会存在这个问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StandardScaler与MinMaxScaler如何选择？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看情况。大多数机器学习算法中，会选择StandardScaler来进行特征缩放，因为MinMaxScaler对异常值非常敏\n",
    "感。在PCA，聚类，逻辑回归，支持向量机，神经网络这些算法中，StandardScaler往往是最好的选择。  \n",
    "\n",
    "MinMaxScaler在不涉及距离度量、梯度、协方差计算以及数据需要被压缩到特定区间时使用广泛，比如数字图像\n",
    "处理中量化像素强度时，都会使用MinMaxScaler将数据压缩于[0,1]区间之中。  \n",
    "\n",
    "建议先试试看StandardScaler，效果不好换MinMaxScaler。  \n",
    "\n",
    "除了StandardScaler和MinMaxScaler之外，sklearn中也提供了各种其他缩放处理（中心化只需要一个pandas广\n",
    "播一下减去某个数就好了，因此sklearn不提供任何中心化功能）。比如，在希望压缩数据，却不影响数据的稀疏\n",
    "性时（不影响矩阵中取值为0的个数时），我们会使用MaxAbsScaler；在异常值多，噪声非常大时，我们可能会选\n",
    "用分位数来无量纲化，此时使用RobustScaler。更多详情请参考以下列表："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/3_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:06.256307Z",
     "start_time": "2019-12-10T12:49:06.218552Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked Survived\n",
       "0  22.0    male        S       No\n",
       "1  38.0  female        C      Yes\n",
       "2  26.0  female        S      Yes\n",
       "3  35.0  female        S      Yes\n",
       "4  35.0    male        S       No"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/Narrativedata.csv', index_col=0)\n",
    "data_copy = data.copy()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### impute.SimpleImputer\n",
    "![](images/3_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:06.794050Z",
     "start_time": "2019-12-10T12:49:06.782429Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:07.317351Z",
     "start_time": "2019-12-10T12:49:07.291115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      "Age         714 non-null float64\n",
      "Sex         891 non-null object\n",
      "Embarked    889 non-null object\n",
      "Survived    891 non-null object\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 34.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:07.809307Z",
     "start_time": "2019-12-10T12:49:07.781983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[29.69911765]\n",
      " [54.        ]\n",
      " [ 2.        ]\n",
      " [27.        ]\n",
      " [14.        ]]\n",
      "[[28.]\n",
      " [54.]\n",
      " [ 2.]\n",
      " [27.]\n",
      " [14.]]\n",
      "[[ 0.]\n",
      " [54.]\n",
      " [ 2.]\n",
      " [27.]\n",
      " [14.]]\n"
     ]
    }
   ],
   "source": [
    "age = data.loc[:, 'Age'].values.reshape(-1, 1)  # 这里将数据升维是为了让sklearn能处理\n",
    "\n",
    "# 实例化模型, 分别填充mean, median, 0\n",
    "impute_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "impute_median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "impute_0 = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "\n",
    "impute_mean = impute_mean.fit_transform(age)\n",
    "impute_median = impute_median.fit_transform(age)\n",
    "impute_0 = impute_0.fit_transform(age)\n",
    "\n",
    "print(impute_mean[5:10])\n",
    "print(impute_median[5:10])\n",
    "print(impute_0[5:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:08.316680Z",
     "start_time": "2019-12-10T12:49:08.305227Z"
    }
   },
   "outputs": [],
   "source": [
    "# 修改原始数据\n",
    "data.loc[:, 'Age'] = impute_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:09.054726Z",
     "start_time": "2019-12-10T12:49:09.028430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      "Age         891 non-null float64\n",
      "Sex         891 non-null object\n",
      "Embarked    889 non-null object\n",
      "Survived    891 non-null object\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 34.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:09.592981Z",
     "start_time": "2019-12-10T12:49:09.568043Z"
    }
   },
   "outputs": [],
   "source": [
    "# 用总数填补Embarked\n",
    "embarked = data.loc[:, 'Embarked'].values.reshape(-1, 1)\n",
    "impute_most_frequent = SimpleImputer(strategy='most_frequent').fit_transform(embarked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:10.100403Z",
     "start_time": "2019-12-10T12:49:10.088844Z"
    }
   },
   "outputs": [],
   "source": [
    "data.loc[:, 'Embarked'] = impute_most_frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:10.607707Z",
     "start_time": "2019-12-10T12:49:10.582368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 4 columns):\n",
      "Age         891 non-null float64\n",
      "Sex         891 non-null object\n",
      "Embarked    891 non-null object\n",
      "Survived    891 non-null object\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 34.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理分类类型特征：编码与哑变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在机器学习中，大多数算法，譬如逻辑回归，支持向量机SVM，k近邻算法等都只能够处理数值型数据，不能处理\n",
    "文字，在sklearn当中，除了专用来处理文字的算法，其他算法在fit的时候全部要求输入数组或矩阵，也不能够导\n",
    "入文字型数据（其实手写决策树和朴素贝叶斯可以处理文字，但是sklearn中规定必须导入数值型）。  \n",
    "\n",
    "然而在现实中，许多标签和特征在数据收集完毕的时候，都不是以数字来表现的。比如说，学历的取值可以是[\"小\n",
    "学\"，“初中”，“高中”，\"大学\"]，付费方式可能包含[\"支付宝\"，“现金”，“微信”]等等。在这种情况下，为了让数据适\n",
    "应算法和库，我们必须将数据进行编码，即是说，将文字型数据转换为数值型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabelEncoder标签(target)专用，能够将分类转换为分类数值（由于是target专用，所以可以接受一维数据）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:12.748556Z",
     "start_time": "2019-12-10T12:49:12.728062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 2, 0])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "y = data.iloc[:, -1]\n",
    "label = LabelEncoder()\n",
    "# label.fit_transform(y)\n",
    "label = label.fit(y)\n",
    "y_encoded = label.transform(y)\n",
    "y_encoded[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:13.348143Z",
     "start_time": "2019-12-10T12:49:13.336197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Unknown', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看分类\n",
    "label.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:14.317934Z",
     "start_time": "2019-12-10T12:49:14.295465Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', 'Yes', 'Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.inverse_transform(y_encoded)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:14.947799Z",
     "start_time": "2019-12-10T12:49:14.936293Z"
    }
   },
   "outputs": [],
   "source": [
    "data.iloc[:, -1] = y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:15.701229Z",
     "start_time": "2019-12-10T12:49:15.676788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked  Survived\n",
       "0  22.0    male        S         0\n",
       "1  38.0  female        C         2\n",
       "2  26.0  female        S         2\n",
       "3  35.0  female        S         2\n",
       "4  35.0    male        S         0"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将上面代码简化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:16.594039Z",
     "start_time": "2019-12-10T12:49:16.572562Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 这里可以接收1维数据\n",
    "data.iloc[:, -1] = LabelEncoder().fit_transform(data.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:17.808113Z",
     "start_time": "2019-12-10T12:49:17.780323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked  Survived\n",
       "0  22.0    male        S         0\n",
       "1  38.0  female        C         2\n",
       "2  26.0  female        S         2\n",
       "3  35.0  female        S         2\n",
       "4  35.0    male        S         0"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OrdinalEncoder特征(feature)专用，能够将分类特征转换为分类数值(由于是特征专用，所以必须输入2维数组)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:19.177557Z",
     "start_time": "2019-12-10T12:49:19.160195Z"
    }
   },
   "outputs": [],
   "source": [
    "data2 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:19.761353Z",
     "start_time": "2019-12-10T12:49:19.749984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['female', 'male'], dtype=object), array(['C', 'Q', 'S'], dtype=object)]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "orc = OrdinalEncoder().fit(data2.iloc[:, 1: -1])\n",
    "orc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:21.484148Z",
     "start_time": "2019-12-10T12:49:21.462134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 2.],\n",
       "       [0., 0.],\n",
       "       [0., 2.],\n",
       "       ...,\n",
       "       [0., 2.],\n",
       "       [1., 0.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orc.transform(data2.iloc[:, 1: -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:23.869364Z",
     "start_time": "2019-12-10T12:49:23.854840Z"
    }
   },
   "outputs": [],
   "source": [
    "# 把第2列到最后一列(不包括最后一列的取出来)\n",
    "data2.iloc[:, 1: -1] = OrdinalEncoder().fit_transform(data2.iloc[:, 1: -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:49:24.669047Z",
     "start_time": "2019-12-10T12:49:24.629102Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Sex  Embarked  Survived\n",
       "0  22.0  1.0       2.0         0\n",
       "1  38.0  0.0       0.0         2\n",
       "2  26.0  0.0       2.0         2\n",
       "3  35.0  0.0       2.0         2\n",
       "4  35.0  1.0       2.0         0"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHotEncoder独热变量，哑变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T12:51:43.497552Z",
     "start_time": "2019-12-10T12:51:43.484075Z"
    }
   },
   "source": [
    "如上面所示，我们把文字型数据变成(分类)数据值型数据，但这样并不一定正确。因为数值有大有小，大小可以用来表示他们之间的层次关系。但是，有些数据之间根本没有层次关系，思考下面几种不同类型是数据：  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 舱门（S, C, Q）  \n",
    "三种取值S，C，Q是相互独立的，也就是它们之间是没有什么特殊的关系。（即，S≠C≠Q）  \n",
    "我们把这种类型的变量称做**名义变量**\n",
    "2. 学历（小学， 初中，高中）  \n",
    "三种取值并非相互独立，可以明显的看出高中>初中>小学，但是学历之间的取值并不能计算的，我们不能说高中=小学+初中。  \n",
    "我们把这种类型的变量称做**有序变量**  \n",
    "3. 体重(>45kg, >90kg, >135kg)  \n",
    "这些类型的数据是可以用数值来衡量的，我们可以说90kg = 30kg + 60kg。  \n",
    "我们把这种类型的变量称做**有距变量**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然而在对特征进行编码的时候，这三种分类数据都会被我们转换为[0,1,2]，这三个数字在算法看来，是连续且可以\n",
    "计算的，这三个数字相互不等，有大小，并且有着可以相加相乘的联系。所以算法会把舱门，学历这样的分类特\n",
    "征，都误会成是体重这样的分类特征。这是说，我们把分类转换成数字的时候，忽略了数字中自带的数学性质，所\n",
    "以给算法传达了一些不准确的信息，而这会影响我们的建模。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "类别OrdinalEncoder可以用来处理有序变量，但**对于名义变量，我们只有使用哑变量的方式来处理**，才能够尽量\n",
    "向算法传达最准确的信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/3_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 处理名义变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T13:08:08.990227Z",
     "start_time": "2019-12-10T13:08:08.961461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked  Survived\n",
       "0  22.0    male        S         0\n",
       "1  38.0  female        C         2\n",
       "2  26.0  female        S         2\n",
       "3  35.0  female        S         2\n",
       "4  35.0    male        S         0"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T13:21:07.888976Z",
     "start_time": "2019-12-10T13:21:07.871476Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "temp = data.iloc[:, 1: -1]\n",
    "ohe = OneHotEncoder().fit(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T13:21:08.596104Z",
     "start_time": "2019-12-10T13:21:08.570308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1.],\n",
       "       [1., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 1.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 1.],\n",
       "       [0., 1., 1., 0., 0.],\n",
       "       [0., 1., 0., 1., 0.]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = ohe.transform(temp).toarray()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T13:21:09.876381Z",
     "start_time": "2019-12-10T13:21:09.846022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_female</th>\n",
       "      <th>x0_male</th>\n",
       "      <th>x1_C</th>\n",
       "      <th>x1_Q</th>\n",
       "      <th>x1_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x0_female  x0_male  x1_C  x1_Q  x1_S\n",
       "0        0.0      1.0   0.0   0.0   1.0\n",
       "1        1.0      0.0   1.0   0.0   0.0\n",
       "2        1.0      0.0   0.0   0.0   1.0\n",
       "3        1.0      0.0   0.0   0.0   1.0\n",
       "4        0.0      1.0   0.0   0.0   1.0"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_data = pd.DataFrame(result ,columns=ohe.get_feature_names())\n",
    "ohe_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T13:21:11.570754Z",
     "start_time": "2019-12-10T13:21:11.537383Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived</th>\n",
       "      <th>x0_female</th>\n",
       "      <th>x0_male</th>\n",
       "      <th>x1_C</th>\n",
       "      <th>x1_Q</th>\n",
       "      <th>x1_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>female</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Sex Embarked  Survived  x0_female  x0_male  x1_C  x1_Q  x1_S\n",
       "0  22.0    male        S         0        0.0      1.0   0.0   0.0   1.0\n",
       "1  38.0  female        C         2        1.0      0.0   1.0   0.0   0.0\n",
       "2  26.0  female        S         2        1.0      0.0   0.0   0.0   1.0\n",
       "3  35.0  female        S         2        1.0      0.0   0.0   0.0   1.0\n",
       "4  35.0    male        S         0        0.0      1.0   0.0   0.0   1.0"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.concat([data, ohe_data], axis=1)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T13:21:18.244947Z",
     "start_time": "2019-12-10T13:21:18.214583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Survived</th>\n",
       "      <th>x0_female</th>\n",
       "      <th>x0_male</th>\n",
       "      <th>x1_C</th>\n",
       "      <th>x1_Q</th>\n",
       "      <th>x1_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Survived  x0_female  x0_male  x1_C  x1_Q  x1_S\n",
       "0  22.0         0        0.0      1.0   0.0   0.0   1.0\n",
       "1  38.0         2        1.0      0.0   1.0   0.0   0.0\n",
       "2  26.0         2        1.0      0.0   0.0   0.0   1.0\n",
       "3  35.0         2        1.0      0.0   0.0   0.0   1.0\n",
       "4  35.0         0        0.0      1.0   0.0   0.0   1.0"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.drop(['Embarked', 'Sex'], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T13:24:46.391162Z",
     "start_time": "2019-12-10T13:24:46.361379Z"
    }
   },
   "outputs": [],
   "source": [
    "# 另一种方式实现\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "data3 = data.copy()\n",
    "\n",
    "# fit， transform一步到位\n",
    "result = OneHotEncoder().fit_transform(data3.iloc[:, 1: -1]).toarray()\n",
    "new_data2 = pd.concat([data3.drop(['Embarked', 'Sex'], axis=1),\n",
    "                       pd.DataFrame(result, columns=['Female', 'male', 'Embarked_C','Embarked_Q', 'Embarked_S'])],\n",
    "                     axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T13:24:56.742747Z",
     "start_time": "2019-12-10T13:24:56.706427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Female</th>\n",
       "      <th>male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Survived  Female  male  Embarked_C  Embarked_Q  Embarked_S\n",
       "0  22.0         0     0.0   1.0         0.0         0.0         1.0\n",
       "1  38.0         2     1.0   0.0         1.0         0.0         0.0\n",
       "2  26.0         2     1.0   0.0         0.0         0.0         1.0\n",
       "3  35.0         2     1.0   0.0         0.0         0.0         1.0\n",
       "4  35.0         0     0.0   1.0         0.0         0.0         1.0"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LabelBinarize标签做哑变量\n",
    "特征可以做哑变量，标签也可以吗？可以，使用类sklearn.preprocessing.LabelBinarizer可以对做哑变量，许多算\n",
    "法都可以处理多标签问题（比如说决策树），但是这样的做法在现实中不常见。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/3_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据类型以及常用统计量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/3_5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarizer二值化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据阈值将数据二值化（将特征值设置为0或1），用于处理连续型变量。大于阈值的值映射为1，而小于或等于阈\n",
    "值的值映射为0。默认阈值为0时，特征中所有的正值都映射到1。二值化是对文本计数数据的常见操作，分析人员\n",
    "可以决定仅考虑某种现象的存在与否。它还可以用作考虑布尔随机变量的估计器的预处理步骤（例如，使用贝叶斯\n",
    "设置中的伯努利分布建模）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T13:38:28.214955Z",
     "start_time": "2019-12-10T13:38:28.198383Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "data10 = data.copy()\n",
    "\n",
    "# 将年龄二值化\n",
    "age = data10.iloc[:, 0].values.reshape(-1, 1)  # 由于Binarizer是特征专用的类，所以不接受一维数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T13:39:41.339024Z",
     "start_time": "2019-12-10T13:39:41.301800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = Binarizer(threshold=30).fit_transform(age)  # 设置阈值为30，即30岁以上为1，30岁一下为0\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KBinsDiscretizer(分段化，离散化)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是将连续型变量划分为分类变量的类，能够将连续型变量排序后按顺序分箱后编码。总共包含三个重要参数："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/3_6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T13:48:49.032391Z",
     "start_time": "2019-12-10T13:48:48.989573Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [4.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [4.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [3.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "# 对年龄进行操作\n",
    "X = data.iloc[:, 0].values.reshape(-1, 1)\n",
    "est = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "est.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T13:48:59.745693Z",
     "start_time": "2019-12-10T13:48:59.731251Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2., 3., 4.])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(est.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T13:50:02.900246Z",
     "start_time": "2019-12-10T13:50:02.882338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est = KBinsDiscretizer(n_bins=5, encode='onehot', strategy='uniform').fit_transform(X)\n",
    "est.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征工程\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征工程的基本思想：  \n",
    "$$全部特征\\Rightarrow最佳特征子集\\Rightarrow算法\\Rightarrow模型评估$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当数据预处理完了，我们可以进行特征工程。特征工程分为下面3个部分：  \n",
    "![](images/3_7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE：**在进行特征工程时必须要了解数据的结构，了解每一个特征代表的意义。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选择（过滤法，嵌入法，包装法，和降维算法）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 过滤法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-11T23:50:14.986439Z",
     "start_time": "2019-12-11T23:50:01.793737Z"
    }
   },
   "outputs": [],
   "source": [
    "# 先导入数据\n",
    "import pandas as pd\n",
    "data = pd.read_csv('data/digit recognizor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-11T23:51:17.745509Z",
     "start_time": "2019-12-11T23:51:12.137653Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据集非常大，而且包含很多特征（784个），如果用svm，或者神经网络可能还跑不出来，用KNN也要跑很久\n",
    "data.describe()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-11T23:53:29.603315Z",
     "start_time": "2019-12-11T23:53:29.581288Z"
    }
   },
   "outputs": [],
   "source": [
    "# 提取特征\n",
    "X = data.iloc[:, 1:]\n",
    "# 提取标签\n",
    "y = data.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "过滤方法通常用作预处理步骤，特征选择完全独立于任何机器学习算法。它是根据各种统计检验中的分数以及相关\n",
    "性的各项指标来选择特征。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方差过滤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### VarianceThreshold(方差阈值法)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以认为，当数据的方差很小(0)时，我们可以认为这个特征基本没有差异或者说(这个特征没有贡献)，很有可能就是这个特征的数值基本相等。所以，对于机器学习来说，**进行特征工程的第一步就是优先消除方差为0的特征**。  \n",
    "`VarianceThreshold`的一个重要参数就是`threshold`，这个参数控制过滤的方差阈值，默认为0。方差过滤法会舍弃方差小于threshold的特征\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T00:01:52.175104Z",
     "start_time": "2019-12-12T00:01:51.150207Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "X_var0 = VarianceThreshold(threshold=0).fit_transform(X)  # 默认Threshold为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T00:03:17.392213Z",
     "start_time": "2019-12-12T00:03:17.375845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_shape: (42000, 784) , X_var0_shape : (42000, 708)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"可以看到，经过方差过滤，特征由原来的784变成708个\"\"\"\n",
    "print('X_shape: {} , X_var0_shape : {}'.format(X.shape, X_var0.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将特征砍掉一半：通过过滤方差的中位数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T00:06:55.273963Z",
     "start_time": "2019-12-12T00:06:54.224426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784) (42000, 392)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_fsvar = VarianceThreshold(threshold=X.var().median()).fit_transform(X)\n",
    "\"\"\"可以明显地看到，特征变为原来的一半\"\"\"\n",
    "print(X.shape, X_fsvar.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T00:07:27.513986Z",
     "start_time": "2019-12-12T00:07:27.493686Z"
    }
   },
   "source": [
    "过滤特定阈值方差的特征。  \n",
    "例如，在二分类，特征的取值服从伯努利分布，它的方差为：  \n",
    "$$DX = p(1- p)$$  \n",
    "其中，X为特征矩阵， p为二分类特征中，某一类特征所占的比例。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T00:11:16.028004Z",
     "start_time": "2019-12-12T00:11:15.112957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784) (42000, 685)\n"
     ]
    }
   ],
   "source": [
    "# 若特征是伯努利随机变量，假设p=0.8，即二分类特征中某种分类占到80%以上的时候删除特征\n",
    "X_bvar = VarianceThreshold(threshold=0.8*(1 - 0.8)).fit_transform(X)\n",
    "print(X.shape, X_bvar.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 方差过滤对模型的影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我为大家准备了KNN和随机森林分别在方差过滤前和\n",
    "方差过滤后运行的效果和运行时间的对比。KNN是K近邻算法中的分类算法，其原理非常简单，是利用每个样本到\n",
    "其他样本点的距离来判断每个样本点的相似度，然后对样本进行分类。KNN必须遍历每个特征和每个样本，因而特\n",
    "征越多，KNN的计算也就会越缓慢。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T00:49:27.485501Z",
     "start_time": "2019-12-12T00:49:17.361229Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/digit recognizor.csv')\n",
    "X = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]\n",
    "\n",
    "# 这里用中位数过滤法\n",
    "X_fsvar = VarianceThreshold(threshold=X.var().median()).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### KNN方差过滤前的表现\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_pre_score = cross_val_score(KNN(), X, y, cv=5).mean()  # 这里暂时不对算法进行修改"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cross_val_score:0.9658569700264943"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spend time : 2357.26731539$≈39min$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  KNN方差过滤后"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spend time : 17.24842890min  \n",
    "cross_val_score:0.9659997478150573  \n",
    "可见，经过特征过滤后的运行时间大大下降了，分数也有所提高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T00:48:08.917275Z",
     "start_time": "2019-12-12T00:48:08.911871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.952952798247698\n"
     ]
    }
   ],
   "source": [
    "print(RFC_pre_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 随机森林方差过滤后的表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T00:51:09.128030Z",
     "start_time": "2019-12-12T00:50:16.874410Z"
    }
   },
   "outputs": [],
   "source": [
    "RFC_pro_score = cross_val_score(RFC(n_estimators=20, random_state=1), X_fsvar, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T00:51:09.591298Z",
     "start_time": "2019-12-12T00:51:09.585050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9521912618525812\n"
     ]
    }
   ],
   "source": [
    "print(RFC_pro_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由上面可以看出，方差(中位数)过滤并没有提高模型的精确度(可能方差过滤掉一些重要的特征)，而且对时间的节省只有一点作用。  \n",
    "为什么随机森林运行如此之快？为什么方差过滤对随机森林没很大的有影响？   \n",
    "这是由于两种算法的原理中涉及到的\n",
    "计算量不同。最近邻算法KNN，单棵决策树，支持向量机SVM，神经网络，回归算法，都需要遍历特征或升维来进\n",
    "行运算，所以他们本身的运算量就很大，需要的时间就很长，因此方差过滤这样的特征选择对他们来说就尤为重\n",
    "要。但对于不需要遍历特征的算法，比如随机森林，它随机选取特征进行分枝，本身运算就非常快速，因此特征选\n",
    "择对它来说效果平平。这其实很容易理解，无论过滤法如何降低特征的数量，随机森林也只会选取固定数量的特征\n",
    "来建模；而最近邻算法就不同了，特征越少，距离计算的维度就越少，模型明显会随着特征的减少变得轻量。因\n",
    "此，**过滤法的主要对象是：需要遍历特征或升维的算法**们，而**过滤法的主要目的**是：在维持算法表现的前提下，帮\n",
    "助算法们降低计算成本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|思考：过滤法对随机森林无效，却对树模型有效？|\n",
    "|:-------|\n",
    "|从算法原理上来说，传统决策树需要遍历所有特征，计算不纯度后进行分枝，而随机森林却是随机选择特征进行计算和分枝，因此随机森林的运算更快，过滤法对随机森林无用，对决策树却有用。  \n",
    "在sklearn中，决策树和随机森林都是随机选择特征进行分枝（不记得的小伙伴可以去复习第一章：决策树，参数random_state），但决策树在建模过程中随机抽取的特征数目却远远超过随机森林当中每棵树随机抽取的特征数目（比如说对于这个780维的数据，随机森林每棵树只会抽取10\\~20个特征，而决策树可能会抽取300\\~400个特征），因此，过滤法对随机森林无用，却对决策树有用。  \n",
    "也因此，在sklearn中，随机森林中的每棵树都比单独的一棵决策树简单得多，高维数据下的随机森林的计算比决策树快很多。  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  | 阈值很小,被过滤掉得特征比较少| 阈值比较大,被过滤掉的特征有很多|\n",
    "|---|----|----|\n",
    "|模型表现| 可能不会有很大影响| 可能变更好，代表被滤掉的特征大部分是噪音<br>也可能变糟糕，代表被滤掉的特征中很多都是有效特征|\n",
    "|运行时间| 可能降低运行时间，取决于过滤的特征数目以及采用的模型|一定可以降低模型的运行时间，算法越复杂，下降的幅度越大|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 超参数threshold的选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般先过滤掉方差为0的特征。然后进行其他特征选择操作。  \n",
    "我们怎样知道，方差过滤掉的到底时噪音还是有效特征呢？过滤后模型到底会变好还是会变坏呢？答案是：每个数\n",
    "据集不一样，只能自己去尝试。这里的方差阈值，其实相当于是一个超参数，要选定最优的超参数，我们可以画学\n",
    "习曲线，找模型效果最好的点。但现实中，我们往往不会这样去做，因为这样会耗费大量的时间。我们只会使用阈\n",
    "值为0或者阈值很小的方差过滤，来为我们优先消除一些明显用不到的特征，然后我们会选择更优的特征选择方法\n",
    "继续削减特征数量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 相关性过滤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们希望选出与标签相关且有意义的特征，因为这样的特征能够为我们提供大量信息。如果特征与标签无关，那只会白白浪费我们的计算内存，可能还会给模型带来噪音。在sklearn当中，我们有三种常用的方法来评判特征与标签之间的相关性：卡方，F检验，互信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 卡方过滤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卡方过滤是专门针对离散型标签（即分类问题）的相关性过滤。卡方检验类feature_selection.chi2计算每个非负\n",
    "特征和标签之间的卡方统计量，并依照卡方统计量由高到低为特征排名。再结合feature_selection.SelectKBest\n",
    "这个可以输入”评分标准“来选出前K个分数最高的特征的类，我们可以借此除去最可能独立于标签，与我们分类目\n",
    "的无关的特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T01:55:37.471223Z",
     "start_time": "2019-12-12T01:55:37.361830Z"
    }
   },
   "source": [
    "另外，如果卡方检验检测到某个特征中所有的值都相同，会提示我们使用方差先进行方差过滤。并且，刚才我们已\n",
    "经验证过，当我们使用方差过滤筛选掉一半的特征后，模型的表现时提升的。因此在这里，我们使用threshold=中\n",
    "位数时完成的方差过滤的数据来做卡方检验（如果方差过滤后模型的表现反而降低了，那我们就不会使用方差过滤\n",
    "后的数据，而是使用原数据）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T02:00:00.486479Z",
     "start_time": "2019-12-12T01:59:57.225150Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/digit recognizor.csv')\n",
    "X = data.iloc[:, 1:]\n",
    "y = data.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T02:02:48.149621Z",
     "start_time": "2019-12-12T02:02:48.143671Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T02:24:03.716359Z",
     "start_time": "2019-12-12T02:24:02.027838Z"
    }
   },
   "outputs": [],
   "source": [
    "X_fsvar = VarianceThreshold().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T02:24:17.712340Z",
     "start_time": "2019-12-12T02:24:17.067614Z"
    }
   },
   "outputs": [],
   "source": [
    "X_fschi = SelectKBest(chi2, k=300).fit_transform(X_fsvar, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T02:24:27.495000Z",
     "start_time": "2019-12-12T02:24:27.469706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 300)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fschi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T02:25:57.895127Z",
     "start_time": "2019-12-12T02:25:35.278265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.953837   0.95275497 0.95320872 0.9540312  0.95509767]\n"
     ]
    }
   ],
   "source": [
    "# 检验模型\n",
    "pre_score = cross_val_score(RFC(n_estimators=20, random_state=1), X_fsvar, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T02:26:47.784100Z",
     "start_time": "2019-12-12T02:26:47.779635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9537859105492401\n"
     ]
    }
   ],
   "source": [
    "print(pre_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T02:26:47.448801Z",
     "start_time": "2019-12-12T02:26:29.620289Z"
    }
   },
   "outputs": [],
   "source": [
    "pro_score = cross_val_score(RFC(n_estimators=20, random_state=1), X_fschi, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T02:26:47.623895Z",
     "start_time": "2019-12-12T02:26:47.619922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9482860428801871\n"
     ]
    }
   ],
   "source": [
    "print(pro_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的分数反而下降了，说明我们过滤掉一些有用的特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 超参数k的选择  \n",
    "那如何设置一个最佳的K值呢？在现实数据中，数据量很大，模型很复杂的时候，我们也许不能先去跑一遍模型看\n",
    "看效果，而是希望最开始就能够选择一个最优的超参数k。那第一个方法，就是我们之前提过的学习曲线："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T02:35:37.607570Z",
     "start_time": "2019-12-12T02:32:01.534422Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "scores = []\n",
    "for i in range(300, 400+1, 10):\n",
    "    X_fschi = SelectKBest(chi2, k=i).fit_transform(X_fsvar, y)\n",
    "    score = cross_val_score(RFC(n_estimators=20, random_state=1), X_fschi, y, cv=5).mean()\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T02:35:38.018059Z",
     "start_time": "2019-12-12T02:35:37.835530Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD6CAYAAACoCZCsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xd0VWXa9/HvlQ4BQgudEEoIIp1QBQXpOjjoWFCKymBFRx0V9Xn09RllxhEVR8eKlWZBsSuCIE0JJQm9hFASQiAkQEIISUi73z9yGCOTkJPknLNPuT5rsdbJyZ29r9sV9y9n73tfW4wxKKWU8j1+VheglFLKGhoASinlozQAlFLKR2kAKKWUj9IAUEopH6UBoJRSPkoDQCmlfJQGgFJK+SgNAKWU8lEBVhdwMU2bNjWRkZFWl6GUUh4lPj7+hDEmvKpxbh0AkZGRxMXFWV2GUkp5FBFJsWecngJSSikfpQGglFI+SgNAKaV8lAaAUkr5KA0ApZTyURoASinlozQAlFLKR7k8AEQkVERGiEgbV+9bKaU8wQe/HuKn3cedvh+7AkBE3hORWBF5spLvtxeR70VknYi8ZHsvQEQOi8hq27/uIhII/AAMAr4VkUsdNhOllPICp/OLmP1jIj/tTnf6vqq8E1hErgP8jTGDROR9EYkyxiRdMOx54FljzAYR+VREhgE5wMfGmMfKbetS4AVjzHcikg0MAXY5bDZKKeXhPo8/Qn5RCVMHRTp9X/Z8AhgGLLa9Xk7ZQftCnYEE2+sMIAwYCPxBRDbZPkEEGGN22Q7+vYFrbdv7HRG5U0TiRCQuMzOzmtNRSinPVVpqWBCbTN92jejWOszp+7MnAEKBNNvrU0DzCsZ8DjwtIuOBscBKYDMw0hjTHwgErio3frxt32cu3JAxZq4xJsYYExMeXmUvI6WU8hprkzJJPpnH1EHtXLI/ewIgF6hje12vop8xxswClgLTgXnGmFxguzHmmG1IHBBVbvwzwELgzzUvXSmlvMv82BSa1gtmXLeWLtmfPQEQz2+nfXoCyZWM2wpEAHNsXy8QkZ4i4g9MALaJyE0i8pTt+w2B7BpVrZRSXibl5FlWJWZwy4AIggJcs0DTnnbQXwHrRKQVMA6YKCKzjDEXrgh6FJhjjMmzff0M8BEgwDfGmBUiEgR8LCJrgaPAbY6YhFJKebqFG1LwF2HSgAiX7bPKADDG5NhW9YwCZhtj0oFtFYx7+oKvdwI9LnivEPhTbQpWSilvk19YwqebUxnbrQXNG4S4bL92PRDGGJPFbyuBlFJKOdDXW9PIKSjm1sGRLt2vtoJQSikLGWOYF5vCJS0bENOukUv3rQGglFIWikvJYs+xHG4d1A4Rcem+NQCUUspC89Yn0yAkgD/2au3yfWsAKKWURY7nFPDjznRu6teWOkH+Lt+/BoBSSlnko42HKTGGyQNdc+fvhTQAlFLKAoXFpXy06TDDo5vRrkmoJTVoACillAV+3JVO5plzLuv7UxENAKWUssD89clENqnL5VHWNb3UAFBKKRfbmXaauJQspgyKxM/PtUs/y9MAUEopF1sQm0KdQH+u72vtk3E1AJRSyoWy8wr5amsa1/ZpTVidQEtr0QBQSikXWhyXyrniUksv/p6nAaCUUi5SUmpYsCGFAe0b06VFA6vL0QBQSilXWbU3g9RT+S7v+lkZDQCllHKRebHJtGgQwqiuFT1a3fU0AJRSygUOZOayLukEkwZEEOjvHode96hCKaW83ILYFAL9hYn9XffIx6poACillJPlnitmSfwRru7ekvD6wVaX8x8aAEop5WRfbknjzLliprrJxd/zNACUUsqJjDHMX59M99Zh9G7b0OpyfkcDQCmlnCj24EmSMnKZasEjH6uiAaCUUk40f30KjeoGMr5nK6tL+S8aAEop5SRp2fks353OTf0iCAl0/SMfq6IBoJRyWyWlhv/5cgePfraN0lJjdTnV9tHGFAAmDXCfpZ/lBVhdgFJKVaS01DDz8+0sSTgCQGTTUGYM72RxVfYrKCrh402pjLikOW0b17W6nArpJwCllNsxxvDU1ztZknCEB0dGcU3PVry0PJFf95+wujS7/bDjGKfOFnLroEirS6mUBoBSyq0YY3j2uz0s2niYu6/oyAMjonjuuu50CK/HXz7eQvrpAqtLtMu82BQ6hIdyWacmVpdSKQ0ApZRbeWn5Pt7/9RC3DY7ksbHRiAihwQG8NbkP+UUlzPgogaKSUqvLvKitqdlsS83m1kGRbrf0szwNAKWU23jt5yReW7Wfif3a8v/+0PV3B89Ozerz/J96EJ+SxXM/7LWwyqrNj00mNMif6/q0trqUi9IAUEq5hXfXHeTF5fu4tndr/n5t9woflj6+ZytuGxzJ+78e4vvtxyyosmonc8/x3bZj/KlvG+qHWPvIx6poACilLLdgQwqzvt/DuG4teOH6HvhXcPA/73+uuoTeEQ2Z+fk2DmTmurBK+3yyOZXCEvd45GNVNACUUpb6PP4IT321kxFdmvHKxN4EVNErPyjAjzcm9SE40J97FsaTV1jsokqrVlxSyqINKVzWqQmdmtW3upwq2RUAIvKeiMSKyJOVfL+9iHwvIutE5CXbewEiclhEVtv+dReRQBH5VESWi8jPItLIkZNRSnmWb7cdZebn2xjSqSmvT+pDUIB9f5O2DKvDKxN7kZSRy/9+uRNj3OMmsRV7Mjh6uoCpbrz0s7wq/2uLyHWAvzFmENBBRKIqGPY88KwxZijQRkSGAT2Aj40xw2z/dgDjgB+NMaOBZcAUR01EKeVZlu9K58FPtxLTrjFzp/atdquEoVHhPDSyM19uSWPRxsNOqrJ65scm07phHUZ0aWZ1KXaxJ26HAYttr5cDQyoY0xlIsL3OAMKAgcAfRGST7RNEgDHmG2PMB7Zx4baxSikfszoxg/s+2kK31mG8d1sMdYNq1pTgvuGdGBYdzjPf7mZbaraDq6yepONnWH/gJJMGRlR5Gstd2FNlKJBme30KqOhpxp8DT4vIeGAssBLYDIw0xvQHAoGrzg8WkQ7AlcCSCzckIneKSJyIxGVmZlZnLkopDxB74CR3LYinU7N6zL+9f61Wyvj5CS/f2Ivw+sHcuyiBrLOFDqy0eubHphAU4MdNMW0tq6G67AmAXKCO7XW9in7GGDMLWApMB+YZY3KB7caY8+u04oAoABEJBj4E7jTGFFWwrbnGmBhjTEx4eHg1p6OUcmfxKVn8ed5mIhrXZcGf+xNWt/bLJBuFBvHGpD5knjnHQ4u3WtI0LqegiCUJRxjfoxVN6rnPIx+rYk8AxPPbaZ+eQHIl47YCEcAc29cLRKSniPgDE4Bttvc/AD40xsTVqGKllEfaceQ0t72/iWb1g1k0fYBDD5Q92zbkqfFdWZ2YyWur9jtsu/b6Iv4IeYUl3DrY/Zd+lmdPAHwFTBGROcCNwC4RmVXBuEeBOcaYPNvXzwALKAuGWGPMChEZB1wLTLWtDHqg9lNQSrm7vek5THl/Iw3qBLLojoE0axDi8H1MHhDBtb1b8/KKfaxLct3p49JSw/zYFHq1bUiPNu71yMeqVHnlxRiTY1vVMwqYbYxJ57e/5suPe/qCr3dSthKo/HtL+e10klLKBxzIzGXyuxsJDvDj4zsG0rqhcw4BIsLfr+3GrqOneeCTrXx3/xBaOWlf5f164AQHT5zl5Zt6On1fjmbXpWpjTJYxZrHt4K+UUnY5fDKPSe9sBGDR9IFENHFuX/y6QQG8ObkvhcWlzPgogcJi5zeNm7c+hSahQVzVvaXT9+VonrFWSSnlcY5m53PLuxsoKC5h4fQBdGpWzyX77Rhej9nX92DL4Wz+8cMep+4r9VQeK/ce5+b+EQQHuN8jH6uiAaCUcriMnAJueWcDp/OKWDBtAF1aNHDp/q/q3pJpl7Xnw/XJfLPtqNP2s3BjCn4i3OKmj3ysigaAUsqhTuaeY9K7G8k4c44Pp/Wje5swS+p44qou9G3XiMeXbGd/xhmHb7+gqIRPN6cyumtzl1xrcAYNAKWUw5zOK2LKe5s4fCqPd2+NoW+7xpbVEujvx+u39KFOoD93L0zg7DnHNo37ZttRsvOKuHVwpEO360oaAEoph8g9V8ytH2xif0Yub0/py+COTa0uiRZhIbx6c28OZubyxBc7HNY0zhjDvPXJRDevz4D21oVcbWkAKKVqLb+whGkfbGZH2mleu6U3w6LdpxnaZZ2a8vDoaL7ZdpQFG1Icss2Ew9nsOprD1MHt3PqRj1XRAFBK1UpBUQl3LogjLuUU/7qpF6MvbWF1Sf/lnis6MqJLM579bjcJh7Nqvb35scnUDwlgQi/3fuRjVTQAlFI1VlhcyoxFCaxLOsHs63syvmcrq0uqkJ+fMOfGXjRvEMJ9ixI4VYumcRlnCvhhxzFu6NuW0OCadTF1FxoASqkaKS4p5cFPt7BybwazJnTj+r5trC7posLqBvLmpL6cyC3kgU+2UFLDpnGfbEqlqMQwxQMe+VgVDQClVLWVlhoe/Xw7P+xI58mrL2HyQM84GHZvE8b/XXMp65JO8OrKpGr/fFFJKYs2pnBF53DaNw11QoWupQGglKoWYwz/+9UOvtySxiOjOzN9aAerS6qWm/u35bo+rXn15yRWJ1bvmVTLdx3neM45j+v6WRkNAKWU3Ywx/O3b3Xy8KZUZwzty35UVPSHWvYkIf5/Qnejm9Xnw062kZefb/bPzYpOJaFyXKzq7zyqn2tAAUErZxRjD7GWJfLg+mT8Pac8jo6OtLqnG6gT58+bkvpSUGO5dlMC54pIqf2bPsRw2HTrFlIHt8Pfz3KWf5WkAKKXs8u+f9/Pm6gNMGhDBk1df4tHr3wHaNw3lhRt6sC01m1nfVd00bn5sCiGBftwQ494Xu6tDA0ApdVE5BUU88MkW5vy0jz/1acOzf+zm8Qf/88Z2a8kdQ9uzYEMKX29Nq3Tc6bwivtqSxoRerWlYN8iFFTqXZy9iVUo5VVzyKR74ZCvpOQX8dVRnZgzvhJ+XnP44b+bYLmxNzebxJTu4pGUDOjev/19jPotPJb+oxCuWfpannwCUUv+luKSUOT/t48a3Y/H3Ez67exB/GRHlNee+ywv09+O1W/oQGhzA3Qvjyb2gaVxpqWHBhhT6RTbi0lbWdDZ1Fg0ApdTvHD6Zx41vx/LqyiQm9G7N938ZQp+IRlaX5VTNG4Tw75t7k3ziLI8t2f67pnFrkjJJOZnH1EGR1hXoJHoKSCn1H19uOcJTX+1CBF69uTfXuGlrB2cY1LEJj4yJZvaPicS0a8Ttl7UHYP76ZJrVD2aMG/Y4qi0NAKUUOQVFPPXVTr7eepR+kY14+aZetGnk3Of3uqO7L+9IQkoWf/9+Dz3aNKRJaBCr92XywIgoggK874SJBoBSPq78hd6HR3Xm3uGdvPJcvz38/ISXbujF+Nd+YcaiBAZ3aoK/CLf098xHPlbF+yJNKWWXii703u+lF3qrI6xuIG9M6sOpvEK+SEhjXPeWNGsQYnVZTqEBoJQP8sULvdXRrXUYsyZ0o06gP9Mui7S6HKfRU0BK+RhfvtBbHTfGtOWanq0ICfS3uhSn0QBQykfohd7q8+aDP2gAKOUT9EKvqogGgFJerLiklFd/3s9rPyfRplFdPrt7kJ7rV/+hAaCUlzp8Mo8HP91CwuFsruvTmr9dcyn1QwKtLku5EQ0ApbyQXuhV9tAAUMqL6IVeVR0aAEp5Cb3Qq6pLA0ApD6cXelVNaQAo5cH0Qq+qDbsCQETeA7oC3xtjZlXw/fbAa0ADYJMx5mERCQAO2v4B3G+M2SEidYH1xpheDpmBUj5KL/Sq2qoyAETkOsDfGDNIRN4XkShjTNIFw54HnjXGbBCRT0VkGJADfGyMeazctvyBxUBDx01BKd+iF3qVo9jzCWAYZQdtgOXAEODCAOgMJNheZwBhlH1i+IOIDAd2AHcBBrgT+KiynYnInbYxRER4ZwtWpWpqa2o2932UwLHTeqFX1Z493UBDgTTb61NA8wrGfA48LSLjgbHASmAzMNIY0x8IBK4yxpQYY45ebGfGmLnGmBhjTEx4eLi981DK6/289zgT58YCaOtm5RD2fALIBerYXtejgtAwxswSkSHAo8A8Y0yuiGw3xpyzDYkDohxRsFK+aEn8EWYu2U7Xlg344PZ+NK0XbHVJygvY8wkgnrLTPgA9geRKxm0FIoA5tq8XiEhP23n/CcC2WtSplM96e80BHv5sGwM7NObjOwfqwV85jD2fAL4C1olIK2AcMFFEZhljnrxg3KPAHGNMnu3rZyg71y/AN8aYFY4qWilfUFpqeG7pHt5Zd4ire7Rkzo09CQ7w7vbEyrXEGFP1IJFGwChgrTEm3elV2cTExJi4uDhX7U4pt1FUUspjn2/niy1pTB3UjqfHX6rn+5XdRCTeGBNT1Ti77gMwxmTx20ogpZQT5RUWM2NRAqsSM/nrqM7cf2UnRPTgrxxP7wRWyo1knS1k2rzNbEvN5h/XdueWAboUWjmPBoBSbuJodj5T39/E4VN5vDGpD2O7tbS6JOXlNACUcgNJx88w9f1N5BYUM+/2/gzq2MTqkpQP0ABQymLxKVn8ed5mAvz8+OSugVzaKszqkpSP0ABQykKr9mZwz6J4mjcIYcG0AUQ00Z4+ynU0AJSyyPm7e7u0qM+Ht/cnvL7e4KVcSwNAKQvMXXuAf/ywl8Edm/D2lL7aw19ZQgNAKRcqLTX888e9zF17kKu7t2TOTXp3r7KOBoBSLlJUUspjS7bzRUIaUwa24/+u0bt7lbU0AJRygfJ39z40sjN/GaF39yrraQAo5WTZeYXc/mHZ3b1/v7Ybkwa0s7okpQANAKWc6j93957Uu3uV+9EAUMpJ9mecYcp7mzhTUMyH0/oxuGNTq0tS6nc0AJRygoTDWUz70HZ3750D6dZa7+5V7kcDQCkHW5WYwT0Ly+7unT+tP+2ahFpdklIV0gBQyoG+SDjCzM+3E6139yoPoAGglIO8s/Ygf/9hD4M6NGHuVL27V7k/DQClaskYwz+X7uXttQe5qnsL5tzYi5BAvbtXuT8NAKVqoaiklMeX7GBJwhEmD4zgb9d007t7lcfQAFCqhvILS5jxUQI/783gwZFRPDAiSu/uVR5FA0CpGsjOK2Tah5vZkprNrAndmDxQ7+5VnkcDQKlqKigqYeLcDRzMPMvrt/Thqu56d6/yTBoASlXTwg0p7E0/wztTYxjVtbnV5ShVY35WF6CUJzmdX8Rrq/YzNKqpHvyVx9MAUKoa3lpzgOy8Ih4f18XqUpSqNQ0ApeyUfrqA9385xIRerbi0lfb2UZ5PA0ApO/1rxT6MgYdHR1tdilIOoQGglB2Sjp9hcVwqkwe2o23julaXo5RDaAAoZYfZyxKpGxTAfVd2sroUpRxGA0CpKsQln+Kn3ce5+4oONA4NsrocpRxGA0CpizDG8NzSvTSrH8y0Ie2tLkcph9IAUOoiftp9nPiULB4c2Zm6QXrfpPIudgWAiLwnIrEi8mQl328vIt+LyDoRecn2XoCIHBaR1bZ/3W3v/01ENovI646bhlKOV1xSyuxliXQID+XGmDZWl6OUw1UZACJyHeBvjBkEdBCRqAqGPQ88a4wZCrQRkWFAD+BjY8ww278dItIXGAL0BzJEZKTDZqKUg30ef4T9GbnMHNOFAH/9sKy8jz2/1cOAxbbXyyk7gF+oM5Bge50BhAEDgT+IyCbbJ4gA4ApgiTHGAMuAobWoXSmnyS8s4eUV++gd0ZAxl2rLB+Wd7AmAUCDN9voUUNH/DZ8DT4vIeGAssBLYDIw0xvQHAoGr7NmWiNwpInEiEpeZmVmduSjlMB+sP8TxnHM8Me4S7fGvvJY9AZAL1LG9rlfRzxhjZgFLgenAPGNMLrDdGHPMNiQOiLJzW3ONMTHGmJjw8PDqzEUph8g6W8ibqw8w8pJm9G/f2OpylHIaewIgnt9O+/QEkisZtxWIAObYvl4gIj1FxB+YAGyrxraUsszrq/Zz9lwxM8dqwzfl3exZ1/YVsE5EWgHjgIkiMssYc+GKoEeBOcaYPNvXzwAfAQJ8Y4xZISJ+wHMi8gplp4rGOmQWSjnIkaw85semcH3fNnRuXt/qcpRyqioDwBiTY1vVMwqYbYxJp+yv+QvHPX3B1zspWwlU/r1S28qfq4FXjDGHalG7chMlpcZrHoQ+Z/k+RODBkZ2tLkUpp7NrbZsxJssYs9h28K8VY0y+MeZzY8zB2m5LWa+opJSrX13HQ59upWxxl+fafTSHL7emcdtlkbRqWKfqH1DKw+mtjapWvt12lL3pZ9ibfoaO4aHcd2VFt4l4htnL9tIgJJB7r9CGb8o36N0tqsZKSw1vrTlAdPP6TOjVipd+2seK3cetLqtG1h84werETGYM70hY3UCry1HKJTQAVI2tSsxg3/Fc7h7WgX/+qQfdWoXx4Kdb2Z9xxurSqsUYwz+X7qVVWAhTB0VaXY5SLqMBoGrsrTUHaN2wDn/o0YqQQH/entKXkEA/7pgfz+n8IqvLs9v3O46x/chp/jo6mpBAf6vLUcplNABUjcQln2JzchbTh7Yn0NYnp1XDOrw5uS9HsvL4y8dbKCl1/4vCRSWlvLAskejm9bm2d2ury1HKpTQAVI28teYAjeoGclO/tr97v19kY/52TTfW7MvkhWWJFlVnv082HSblZB6PjYv2mqWsStlLA8DB8gqLyS8ssboMp0pMP8OKPRncOjiywh75twyIYNKACN5ac4Cvt6ZVsAX3kHuumFdWJjGgfWOGRzezuhylXE4DwIFKSg03vBXLlPc2evya+It5e+0B6gT6c+tFLpg+Pf5S+kc25rEl29mZdtp1xVXDu+sOciK3kMfHddGGb8onaQA40Dfb0th1NIe4lCyWe+hyyKqkZefzzdajTOzflkYXeT5uUIAfb0zuQ+O6Qdw5P44TuedcWGXVMs+c4521BxnXrQW9IxpZXY5SltAAcJDC4lJeWr6Pri0b0DE8lBeWJXrERdDqendd2Q3c04d2qHJs03rBzJ0aw8mzhdy7MIHC4lJnl2e3f/+cREFxKY+Oiba6FKUsowHgIB9vOsyRrHxmjo3mkdHR7M/I5YuEI1aX5VBZZwv5ZFMq1/RqRWs7WyV0ax3G7Ot7sCn5FM98t8vJFdon+cRZPtp4mIn92tIhvJ7V5ShlGW0F4QBnzxXz75/LLiZe0bnsGQY92oTxrxVJjO/ZymvWls+LTSa/qIS7r+hYrZ/7Y6/W7D6Ww9trDtK1ZRi3DIhwToF2enF5IoH+fjwwwnPbVijlCPoJwAHe/+UQJ3ILmTm27GKiiPDY2C6kZeezaONhq8tziLzCYuatT2bkJc1q1CZ55pguXNE5nKe/2Ulc8iknVGifbanZfLf9GHcMbU+zBiGW1aGUO9AAqKVTZwuZu/Ygo7o2p2+73y4mXtapKUM6NeX1VfvJPVdsYYWO8enmVLLyiqr91/95/n7CqxN707phHe5emMDR7HwHV1i18y0fGocGccflVV/DUMrbaQDU0pur95NbWFzhxcRHx0Rz6mzhfy6ceqqiklLeXXeIfpGNiIms+SMSw+oG8s7UGAqKSrhrQTwFRa69X2Jt0gliD57k/is7UT9EG74ppQFQC0ez85kXm8J1vSt+elTPtg25qnsL3ll7kJNutgyyOr7ddpS07Pwa//VfXlTz+rx8Uy92pJ3miS92uOx+idLSsr/+2zauw6QB7VyyT6XcnQZALbyyIgkMPDiy8ouJD4+OpqC4lNdXHXBhZY5jjOHtNQeJbl7fYXfLjuranIdHdebLLWm8u841D4X7elsae47l8MjoaIIC9NdeKdAAqLH9Gbl8Fp/KpIERtG1ct9JxHcPrcUPfNizckMKRrLxKx7mrVYkZJB4/w11XdMDPgb1y7ruyE+O6teC5pXtYuy/TYdutyLniEl5cto9urRswvkcrp+5LKU+iAVBDLy1PpE6gPzOGV/30qAdGRoHAv1YkuaAyx3pzdVnL5/E9HXvgFBFevKEnnZvX576PEkg+cdah2y9vQWwKadn5PD72EoeGmFKeTgOgBralZrN0ZzrTh3agab3gKse3DKvDrYPa8UXCEfYd95yHpVTU8tmRQoMDeGdqDH5+wh3z45yyWiqnoIjXVu1naFRThkQ1dfj2lfJkGgA18MKyRBqHBjF9aHu7f+beYZ0IDQrgRQ9okXxeZS2fHalt47q8fksfDp44y0OfbqXUwe0z3l5zgOy8Ih4b28Wh21XKG2gAVNMvSSf4Zf8JZgyv3lLCRqFB3Hl5B5bvPk7C4SwnVugY+45fvOWzI13WqSn/e9Ul/LT7OK+sdNxpsvTTBbz3yyH+2KsV3VqHOWy7SnkLDYBqMMYwe9leWjesw6QatDOYNqQ9TesF8fzSvW7fLvqtNVW3fHak2y+L5Pq+bXhlZRI/7jzmkG2+snIfJaWGR0ZrwzelKqIBUA0/7kxn+5HTPDgyqkb9fUKDA7j/yig2HjrF2qQTTqjQMext+exIIsKsCd3o2bYhf128jcT02l0r2Z+Ry6ebU5k8sN1FV2kp5cs0AOxUXFLKC8sTiWpWj+v6tKnxdm7uH0GbRnWY/eNeh5/vdpT3bGvz7Wn57Eghgf7MndKXesEB3DE/juy8whpva/aPe6kbFMB9dqzSUspXaQDYaUnCEQ5mnuWRMbV7dmxQgB8Pj+7MrqM5/OCgUx2OlHW2kI83Ha5Wy2dHat4ghLem9CX9dAH3fbSF4pLqP0MgPuUUy3cf567LO9DEjlVaSvkqDQA7FBSV8K8VSfRq25DRXZvXenvX9GxNlxb1eWn5PopqcIBzpvmxKTVq+exIfSIaMWtCN37Zf4J/Lt1brZ81xvDcD3sJrx/Mn6uxSkspX6QBYIcFsSkcO13AzLHRDnl2rL+f8OiYaA6dOMtnce7z0Ji8wmI+XH+IEV1q1vLZkW7s15bbBkfy7i+HWBJv/3+jFXsyiEvJ4sGRUU5fvaSUp9MAqEJOQRGvry67kWhwR8fdSHRll2bEtGvEKyv3kV/o2q6YlVlsa/l8zzDr/vov73+vvoRBHZrwxJc72JaaXeX44pJSZv+4lw5NQ7kxxnkRCjOXAAAMfElEQVT3LijlLTQAqvDO2oNk5xUxc4xjbyQSEWaO7cLxnHPMi0126LZroqiklHfWHSKmXe1aPjtSoL8fr0/qQ3i9YO5aEE/GmYKLjl+ScISkjFxmjo12yp3LSnkb/b/kIjLPnOPddYe4ukdLurdx/I1E/ds3Znh0OG+s2s/pvCKHb786vtte1vLZXf76P69xaBDvTI3hdH4R9yxM4FxxxZ+W8gtLePmnsus0Yy5t4eIqlfJMGgAX8drPSRSWlPLwqM5O28ejY7qQU1DM22utaxdtjOGt1Qfp3Lyew1o+O1LXVg148YaexKdk8fTXuyq8ie7D9cmk5xTwxLguDrlOo5Qv0ACoxOGTeXy06TA3xrSlQ3g9p+2na6sG/LFXK97/9RAZORc/xeEs51s+331FR7ftlnl1j5bMGN6RTzansnBDyu++l3W2kDdW72dEl2YM6NDEogqV8jx2BYCIvCcisSLyZCXfby8i34vIOhF56YLvNReRLVWNczcvr9iHnwgPjKj8YS+O8tdRnSkuMbz6szXtot9afdApLZ8d7eFR0Yzo0oy/fbubDQdP/uf9N1aXPXd5pjZ8U6paqgwAEbkO8DfGDAI6iEhFR8TngWeNMUOBNiIyrNz3XgTq2DHObew5lsNXW9O47bJIWoSFOH1/7ZqEcnP/CD7ZlErKSef1xa9IfMopNiWf4s9DnNPy2ZH8/ISXJ/Yiokld7l2UwJGsPI5k5TFvfQp/6tOG6BbWLl1VytPY83/8MGCx7fVyYEgFYzoDCbbXGUAYgIhcCZwF0i82rjwRuVNE4kQkLjPTuU+KqsyLyxKpFxzAPS68Ger+KzsR6O/HnJ/2uWyfAG+uPkjDuoFM7O8ZyyYbhJQ9WL6opJQ758fz3NK9IGWfopRS1WNPAIQCabbXp4CKboX9HHhaRMYDY4GVIhIEPAU8frFxF27IGDPXGBNjjIkJDw+3fyYOEpd8ipV7M7j7io40rOuaRmgAzRqEMG1IJF9vPcquo6ddss+yls/HuXWQ81s+O1LH8Hq8OrE3e9Jz+H77MW4fHEkrC9pWKOXp7AmAXH47hVOvop8xxswClgLTgXnGmFzKDvxvGGOyqxjnNowxPP9jWRuB2y+LdPn+77y8I2F1Al320Ji31xwsa/k8ONIl+3Ok4V2a8dTVXenSor7bLV1VylPYEwDx/HbapyeQXMm4rUAEMMf29UhghoisBnqJyLuVjHMbqxMz2ZycxV9GWNNGIKxOIPcO68iqxEw2lrvI6Qxp2fl8vTWNm/q1pbGLWj472rQh7fnxwctd+klNKW9iTwB8BUwRkTnAjcAuEZlVwbhHgTnGmDwAY8zlxphhxphhwFZjzPSKxrmL0tKyv/7bNanLRCc+ArEqtw6OpHmDYGYvS3TqQ2N+a/msDdOU8lVVBoAxJoeyC8EbgOHGmG3GmP9aDmqMedoYs6CSbQyzZ5yVvt1+lL3pZ/jrqM6WroYJCfTngRGdiU/JYuWeDKfsI+tsIZ9sPsw1PVvRppE+LEUpX2XXkc4Yk2WMWWyMSa96tOcpLC7lpeX7uKRlA8b3sH4t/A0xbWjfNJQXliVS4oSHxsyPTSGvsIS7LGz5rJSynnsv/HaRTzcf5vCpPGaOjXaLO2ED/cseGpN4/Axfb02r+geqoXzLZ103r5Rv8/kAyCss5pWV++kf2ZhhnV2/7LQyV3VrSbfWDZjz075KG6DVxPmWz3fryhmlfJ7PB8AHvyZzIvecwx724ih+fsLMMV04kpXPxxsPO2Sb5Vs+93OTls9KKev4dABknS3krdUHGHlJM7fpgV/e0KimDOrQhNdW7efsueJab+98y2crH/eolHIfPh0Ab605QG5hMY+Miba6lAqVPTQmmhO5hbz/y6Fabat8y+cru7hfy2ellOv5bAAcO53Ph+uTubZXa7q0aGB1OZXqHdGIMZc2Z+7ag5w6W1jj7Zxv+XzX5e7b8lkp5Vo+GwCvrkyi1Bge8oAmYo+MjuZsYTFvrt5f4228tfogrcJCuKaX9ctclVLuwScD4EBmLovjjjBpQDvaNnb/G6Gimtfnuj5tmBebwtHs/Gr//PmWz9OHdnD7ls9KKdfxyaPBnOX7CA7wY8bwTlaXYrcHR0aBgVdWVP+hMZ7W8lkp5Ro+FwDbj2Tz/Y5jTB/SnvD6wVaXY7c2jeoyeWA7PotPZX+G/U1Ukzy05bNSyvl8LgBeWJZIo7qBTL+8g9WlVNuM4R2pE+jPS8vtbxf91pqDhAT6eWTLZ6WUc/lUAKzff4J1SSeYMbwTDUICrS6n2prUC+aOyzuwdGc621Kzqxx/1NbyeWK/CI9t+ayUch6fCQBjDM8vS6RlWAiTB7azupwamz60A41Dg5i9bG+VY99ddwiDtnxWSlXMZwJg2a7jbEvN5qGRnQkJ9Le6nBqrFxzAfcM78ev+k/ySdKLScdl5ZS2f/6gtn5VSlfCJACguKeXF5Yl0DA/luj6trS6n1iYNjKB1wzrMXra30ofGaMtnpVRVfCIAvtiSxv6MXB4dE02AF6yDDw7w56FRndl+5DQ/7vzvRzTkF5bw4fpkrtSWz0qpi/D8o2EVCopK+NdP++jZJowxl7awuhyHubZ3a6Ka1eOF5YkUl5T+7nuL41I5dbZQH5aulLoorw+AhRtSOHq6gMfGdnGrds+15e8nPDImmoOZZ1mScOQ/7xeVlDJ37UH6astnpVQVvDoAzhQU8fqq/Qzp1JTBnZpaXY7Dje7anF5tG/KvFUkUFJU9NOb77cdIy87nHj33r5SqglcHwDvrDpGVV8SjbtruubZEhMfGduHY6QIWxKaUtXxec4CoZtryWSlVNa/tDXAi9xzvrjvIVd1b0LNtQ6vLcZpBHZtweedwXl+9n2YNgtmbfoaXbuipLZ+VUlXy2k8Ar/28n3PFpTw82jv/+i9v5phosvOKeOSzbdryWSllN68MgNRTeSzamMINfdvQMbye1eU4XbfWYfyhR0uKSoy2fFZK2c0rTwEVlZQyNCqcB0ZGWV2Ky/zPVZcQXj+Ym/tHWF2KUspDSGV3krqDmJgYExcXZ3UZSinlUUQk3hgTU9U4PVeglFI+SgNAKaV8lAaAUkr5KA0ApZTyURoASinlozQAlFLKR2kAKKWUj9IAUEopH+XWN4KJSCaQUotNNAUqf3Cu9/G1+YLO2VfonKunnTEmvKpBbh0AtSUicfbcDectfG2+oHP2FTpn59BTQEop5aM0AJRSykd5ewDMtboAF/O1+YLO2VfonJ3Aq68BKKWUqpy3fwJQSilVCY8PABFpLCKjRKSp1bW4is7ZN+iclbN5dACISCPgO6A/sEpEwkXkPRGJFZEny437r/c8VQVzbiciS0VkuYh8KSJBtnHePOdw2/vNRWRLuXG+MOc3RGR8uXFePWcR+UFE4kTk7XLjvGbO55X/XXblMcyjAwDoAfzVGPN3YBlwJeBvjBkEdBCRKBG57sL3LKzXES6c8wRgjjFmNJAOjPWBOfexvf8iUAfAF+YsIkOBFsaYb8En5nwLsMi2Fr6+iMR44ZzPexGoU9H8nDlnjw4AY8waY8wGEbmcsr8axgCLbd9eDgwBhlXwnseqYM4fGGN+sn07HMjA++ccKyJXAmcpCz3w/jlvAN4BkkXkj7Zhw/DuOWcD3USkIdAWSMXL5gxwwe/yMFx4DPPoAAAQEQFuArIAA6TZvnUKaA6EVvCeR7tgzkW29wYBjYwxG/D+OQvwFPB4uSHePufJwG5gNtBfRO7H++e8GmgH/AXYQ9kcvWrOtlO25X+XK5qf0+bs8QFgyswAtgODsZ0SAOpRNr/cCt7zaBfM+RoRaQz8G5hmG+Ltc34QeMMYk11uiLfP+T5grjEmHVgIDMf757wauNsY8wywF7gd75vz4/z+d7mi+Tltzh79H09EHhORqbYvGwL/5LePRz2BZCC+gvc8VgVzzgY+A54wxpxvnOftcx4LzBCR1UAvEXkX75/zh0AH29cxlDVJ9PY5NwS6i4g/MICyT/heNWdgJOV+l4HxuPAY5tE3gtlWDSwGgoGdwBPAWmAlMA4YSNkvzbry7xljTltSsANUMOcdwD+AbbYhbwJL8e45zzC2X1wRWW2MGSYiDfDuOT8GvE/Zx/9A4HrgDN4953mUzbkdEAtcS9kfrV4z5/JsIXANF8wPJx7DPDoAKmL7JRoFrLV9XK7wPW+nc9Y5eytvn7Mrj2FeFwBKKaXs49HXAJRSStWcBoBSSvkoDQCllPJRGgBKKeWjNACUUspH/X/IWPVSzhNbCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(300, 400+1, 10), scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T02:40:26.182668Z",
     "start_time": "2019-12-12T02:36:09.184080Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "scores = []\n",
    "for i in range(390, 500+1, 10):\n",
    "    X_fschi = SelectKBest(chi2, k=i).fit_transform(X_fsvar, y)\n",
    "    score = cross_val_score(RFC(n_estimators=20, random_state=1), X_fschi, y, cv=5).mean()\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T02:40:43.299582Z",
     "start_time": "2019-12-12T02:40:43.188478Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(390, 500+1, 10), scores)  # 可以看到在470左右取到最大值\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T02:41:31.482673Z",
     "start_time": "2019-12-12T02:41:31.456881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9543812394392164"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">用卡方检验找出k值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">p值法的大概原理是：利用小概率事件不可能发生，如果我们认为小概率事件发生的概率正常为p，如果超过p，那么我们就可以认为这件事不是小概率了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卡方检验的本质是推测两组数据之间的差异，其检验的原假设是”两组数据是相互独立的”（即，两组数据不相关）。卡方检验返回卡方值和\n",
    "P值两个统计量，其中卡方值很难界定有效的范围，而p值，我们一般使用0.01或0.05作为显著性水平，即p值判断\n",
    "的边界，具体我们可以这样来看："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/3_8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从特征工程的角度，我们希望选取卡方值很大，p值小于0.05的特征，即和标签是相关联的特征。而调用\n",
    "SelectKBest之前，我们可以直接从chi2实例化后的模型中获得各个特征所对应的卡方值和P值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T02:45:41.074745Z",
     "start_time": "2019-12-12T02:45:40.477926Z"
    }
   },
   "outputs": [],
   "source": [
    "chi_values, chi_pvalues = chi2(X_fsvar, y) # 卡方检验会返回两个变量，一个是卡方分布的分布值，一个是P值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T02:53:10.775460Z",
     "start_time": "2019-12-12T02:53:10.762534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以通过p过滤，\n",
    "p = 0.05\n",
    "(chi_pvalues > p).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T02:53:30.169423Z",
     "start_time": "2019-12-12T02:53:30.161983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "708"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#k取多少？我们想要消除所有p值大于设定值，比如0.05或0.01的特征：\n",
    "p = 0.05\n",
    "k = chi_values.shape[0] - (chi_pvalues > p).sum()\n",
    "#X_fschi = SelectKBest(chi2, k=填写具体的k).fit_transform(X_fsvar, y)\n",
    "#cross_val_score(RFC(n_estimators=10,random_state=0),X_fschi,y,cv=5).mean()\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">用F检验选择k值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F检验，又称ANOVA，方差齐性检验，是用来捕捉每个特征与标签之间的线性关系的过滤方法。它即可以做回归也\n",
    "可以做分类，因此包含**feature_selection.f_classif**（F检验分类）和**feature_selection.f_regression**（F检验回\n",
    "归）两个类。其中F检验分类用于标签是离散型变量的数据，而F检验回归用于标签是连续型变量的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "和卡方检验一样，这两个类需要和类**SelectKBest**连用，并且我们也可以直接通过输出的统计量来判断我们到底要\n",
    "设置一个什么样的K。需要注意的是，F检验在数据服从正态分布时效果会非常稳定，因此如果使用F检验过滤，我\n",
    "们会先将数据转换成服从正态分布的方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F检验的本质是寻找两组数据之间的线性关系，其原假设是”数据不存在显著的线性关系“。它返回F值和p值两个统\n",
    "计量。和卡方过滤一样，**我们希望选取p值小于0.05或0.01的特征，这些特征与标签时显著线性相关的**，而p值大于\n",
    "0.05或0.01的特征则被我们认为是和标签没有显著线性关系的特征，应该被删除。以F检验的分类为例，我们继续\n",
    "在数字数据集上来进行特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 小结\n",
    "+ 卡方检验(一般检验特征与标签的关系)：用于检验两组数据是否相互独立(**原假设两组数据是相互独立的**)。  \n",
    "卡方检验会返回一个chi_values和一个chi_pvalues。当chi_pvalues中values>p，（我们认为小概率事件发生的概率为p）我们就可以认为这两组数据不是相互独立的。  \n",
    "既然两组数据不是相互独立(即，特征与标签不是相互独立)，也就是他们是相关的，那我们就不能用该特征预测标签。  \n",
    "所以，我们可以用$特征的数量 - 线性不是相互独立的特征的数量 = k$\n",
    "+ F检验(检验特征与标签的关系)：用于检验两组数据是否线性相关(**原假设两组数据不存在显著的线性关系**)  \n",
    "F检验与卡方检验一样会返回一个F_values和一个F_pvalues。当F_pvalues中的values>p，我们就可以认为这两组数据是显著性相关的。所以我们需要过滤这些数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T03:06:27.586014Z",
     "start_time": "2019-12-12T03:06:26.995247Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "F_values, F_pvalues = f_classif(X_fsvar, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T03:09:51.441287Z",
     "start_time": "2019-12-12T03:09:51.430376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 0.05\n",
    "(F_pvalues>p).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T03:12:45.800115Z",
     "start_time": "2019-12-12T03:12:45.112132Z"
    }
   },
   "outputs": [],
   "source": [
    "p = 0.05\n",
    "k = X_fsvar.shape[1] - (F_pvalues>p).sum()\n",
    "X_fsf = SelectKBest(f_classif, k=k).fit_transform(X_fsvar, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T03:13:49.640669Z",
     "start_time": "2019-12-12T03:13:27.668801Z"
    }
   },
   "outputs": [],
   "source": [
    "score = cross_val_score(RFC(n_estimators=20, random_state=1), X_fsf, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T03:17:18.806761Z",
     "start_time": "2019-12-12T03:17:18.780971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "只过滤方差为0的：0.9537859105492401， F检验后的:0.9537625033693994\n"
     ]
    }
   ],
   "source": [
    "\"\"\"虽然分数下降了，但下降的幅度不是很明显，我们可以在运行时间与准确度去平衡\"\"\"\n",
    "print('只过滤方差为0的：{}， F检验后的:{}'.format(pre_score.mean(), score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">使用互信息法选出k值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "互信息法是用来捕捉每个特征与标签之间的任意关系（包括线性和非线性关系）的过滤方法。和F检验相似，它既\n",
    "可以做回归也可以做分类，并且包含两个类**feature_selection.mutual_info_classif**（互信息分类）和\n",
    "**feature_selection.mutual_info_regression**（互信息回归）。这两个类的用法和参数都和F检验一模一样，不过\n",
    "互信息法比F检验更加强大，F检验只能够找出线性关系，而互信息法可以找出任意关系。  \n",
    "\n",
    "互信息法不返回p值或F值类似的统计量，它返回“每个特征与目标之间的互信息量的估计”，这个估计量在[0,1]之间\n",
    "取值，为0则表示两个变量独立，为1则表示两个变量完全相关。以互信息分类为例的代码如下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T03:30:08.143578Z",
     "start_time": "2019-12-12T03:25:53.152160Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif as MIC\n",
    "\n",
    "result = MIC(X_fsvar, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T03:41:36.643118Z",
     "start_time": "2019-12-12T03:37:21.459007Z"
    }
   },
   "outputs": [],
   "source": [
    "k = X_fsvar.shape[1] - (result<=0).sum()\n",
    "X_fsmic = SelectKBest(MIC, k=k).fit_transform(X_fsvar, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T03:41:58.247127Z",
     "start_time": "2019-12-12T03:41:36.882510Z"
    }
   },
   "outputs": [],
   "source": [
    "score = cross_val_score_val_score_val_score(RFC(n_estimators=20, random_state=1), X_fsmic, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T03:44:08.596934Z",
     "start_time": "2019-12-12T03:44:08.586493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9537859105492401 0.9527383252946129\n"
     ]
    }
   ],
   "source": [
    "print(pre_score.mean(), score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然了，无论是F检验还是互信息法，大家也都可以使用学习曲线，只是使用统计量的方法会更加高效。当统计量\n",
    "判断已经没有特征可以删除时，无论用学习曲线如何跑，删除特征都只会降低模型的表现。当然了，如果数据量太\n",
    "庞大，模型太复杂，我们还是可以牺牲模型表现来提升模型速度，一切都看大家的具体需求"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 过滤法总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到这里我们学习了常用的基于过滤法的特征选择，包括方差过滤，基于卡方，F检验和互信息的相关性过滤，讲解\n",
    "了各个过滤的原理和面临的问题，以及怎样调这些过滤类的超参数。通常来说，我会建议，先使用方差过滤，然后\n",
    "使用互信息法来捕捉相关性，不过了解各种各样的过滤方式也是必要的。所有信息被总结在下表："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/3_9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded嵌入法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "嵌入法是一种让算法自己决定使用哪些特征的方法，即特征选择和算法训练同时进行。在使用嵌入法时，我们先使\n",
    "用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据权值系数从大到小选择特征。这些权值系\n",
    "数往往代表了特征对于模型的某种贡献或某种重要性，比如决策树和树的集成模型中的feature_importances_属\n",
    "性，可以列出各个特征对树的建立的贡献，我们就可以基于这种贡献的评估，找出对模型建立最有用的特征。因此\n",
    "相比于过滤法，嵌入法的结果会更加精确到模型的效用本身，对于提高模型效力有更好的效果。并且，由于考虑特\n",
    "征对模型的贡献，因此无关的特征（需要相关性过滤的特征）和无区分度的特征（需要方差过滤的特征）都会因为\n",
    "缺乏对模型的贡献而被删除掉，可谓是过滤法的进化版"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/3_10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "过滤法中使用的统计量可以使用统计知识和常识来查找范围（如p值应当低于显著性水平0.05），而嵌入法中使用\n",
    "的权值系数却没有这样的范围可找——我们可以说，权值系数为0的特征对模型丝毫没有作用，但当大量特征都对\n",
    "模型有贡献且贡献不一时，我们就很难去界定一个有效的临界值。这种情况下，模型权值系数就是我们的超参数，\n",
    "我们或许需要学习曲线，或者根据模型本身的某些性质去判断这个超参数的最佳值究竟应该是多少。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另外，嵌入法引入了算法来挑选特征，因此其计算速度也会和应用的算法有很大的关系。如果采用计算量很大，计\n",
    "算缓慢的算法，嵌入法本身也会非常耗时耗力。并且，在选择完毕之后，我们还是需要自己来评估模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-12T03:43:10.990685Z",
     "start_time": "2019-12-12T03:43:10.973780Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SelectFromModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
